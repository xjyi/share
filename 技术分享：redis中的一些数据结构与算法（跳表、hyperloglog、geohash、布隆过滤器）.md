<font size='4'>


[toc]

#### Redis中的一些数据结构与算法
    1. 跳表
    2. HyperLoglog 
    3. GeoHash 算法

#### 1. 跳表
##### 1.1 跳表在redis中的应用
    1. zset 应用
        - 排行榜（获取前三名）：zrevrangebyscore mykey +inf -inf withscores limit 0 3
        
        - 区间搜索：  zrangebyscore mykey 100 300
        
    2.  zset数据结构
        1. 压缩列表
            - 所有数据的大小都要小于64字节、且元素个数要小于128个
        2. 跳表
        
##### 1.2 跳表数据结构介绍
    1. 对比红黑树/ 平衡树 这样的树形结构
        1. 性能考虑
            - 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作
            - 相对来说跳跃表的变化只涉及局部 
            
        2. 实现考虑
            - 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观
            
    2. 回顾基本的线性数据结构
        - 数组
            - 有序数组二分查找：O(logn)   <!--数组随机查找的时间复杂度：O(1)-->
            - 插入的时间复杂度：O(n)
            - 其他确定：需要连续内存，不适合存储较大数据量
            
        - 链表
            - 查找时间复杂度：O(n)
            - 插入时间复杂度：O(1)


    4. 跳表：
![image](https://note.youdao.com/yws/public/resource/c9fd6bcc859bb3da286bf905e764f666/xmlnote/8CF3CE868F0D424EB0AC88811DB8F0D3/31710)

##### 1.3 复杂度
    1. 时间复杂度： O(logn)
    2. 空间复杂度： O(n)
    
###### 时间复杂度证明
    1. 分析
        1. 第一级索引的结点个数大约就是n/2
        2. 第二级索引的结点个数大约就是n/4
        3. 第三级索引的结点个数大约就是n/8
        ...
        - 依次类推，第k级索引的结点个数是第k-1级索引的结点个数的1/2
        
        - 那么第k级索引结点的个数就是n/(2^k)
    
    2. 假设索引高度是h
        - 最高级的索引有2个结点
        - 通过上面的公式，我们可以得到n/(2^h)=2
        
        - 得出： h=log2n-1
            - 包含原始链表这一层，整个跳表的高度就是log2n
            - 每一层都要遍历m个结点，那在跳表中查询一个数据的时间复杂度就是O(m*logn)
            - 本例子中m是3，反正是常量
        
    3. 时间复杂度
        - O(logn)

###### 空间复杂度证明
    1. 索引的节点数
        - n/2+n/4+n/8…+8+4+2
        - 是一个等比数列
            - 根据等比数列的求和公式：(a1-anq)/(1-q)
            - a1为首项,an为第n项,q 为等比
            
        - 等于n-2
        
    2. 所以，跳表的空间复杂度是O(n)
    
    3. 在实际的软件开发中，原始链表中存储的有可能是很大的对象
        - 而索引结点只需要存储关键值和几个指针，并不需要存储对象
        - 所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了
        
##### 1.4 跳表的维护：索引动态更新
    1. 索引如果不维护，大量的数据新增修改，可能会导致跳表退化，极端情况下会退化为普通链表

	2. Java简单实现:如果跳表是每两个节点抽一个索引出来，则下层有50%的概率会被抽到。每上升一层都是50%。
         
```
    private static final float SKIPLIST_P = 0.5f;
    private int randomLevel() {
        int level = 1;
        while (Math.random() < SKIPLIST_P && level < MAX_LEVEL){
          level += 1;
        }
        return level;
    }
```

---

#### 2. HyperLoglog
    - 应用：基数统计(Cardinality Counting) 通常是用来统计一个集合中不重复的元素个数
        -  例如：统计网站上每个网页的UV(独立访客，每个用户每天只记录一次)
    
    - 其他实现方式
        1. set 
            - 缺点：每个网页一个set，海量数据会耗费内存
            
        2. bitmap
            - 位图最小存储单位是bit ，能大量节省空间。但是在海量数据时还是不合适
    
    - HyperLoglog
        - 不追求绝对精确的情况下，不直接存储数据。使用概率算法来统计(特别适合海量数据)
        - 只需要 12 K 内存，在 标准误差 0.81% 的前提下，能够统计 2^64 个数据
    
#####   2.1 简单使用
    1. 添加元素
        PFADD mykey a b c d e f g h i j
    
    2. 查看近似基数
        PFCOUNT mykey
    

#####   2.2 HyperLoglog原理
    1. 算法的本源是伯努利过程
        - 伯努利过程即个抛硬币实验的过程
        - 第一次抛到正面的概率是1/2
        - 连续2次正面：1/4
        ... 
        
    2. 连续正面的次数越多，这个事件的概率越小
        - 充分必要条件： 即可以根据连续多次正面的实验结果，反推进行试验的次数
    
#####  2.3 HyperLogLog 模拟伯努利过程
    1. 添加元素时，通过Hash函数，将元素转为64位比特串（二进制）
    
    2. 这个比特串，从低位往高位看就是一个伯努利过程
        - 连续的0的个数越多（1出现的越晚），说明数据的基数越多
    
    3. 改善误差
        - 由于可能出现一些特殊数据导致较大的误差
            - HyperLogLog中引入分桶平均的概念，计算 m 个桶的调和平均值
            
        1. HyperLogLog 一共分了 2^14 个桶，也就是 16384 个桶
            - 每个桶占6个bit
        
        2. Hash出来的64位数据，低14位作为桶的角标
            - 高50位，从低到高，在桶中记录连续0的个数
            - 新的数据，跟Hash桶中的记录比较，保留连续0个数做的那个
        
        3. 每个桶的数据进行平均，结果修正等，得到估算的基数值

##### 2.4 储存
    1. 密集存储
        - 使用2^14 个 6 bit的桶（6bit，可以完全存储 64-14 = 50个数据）
        - 一个字节8bit，因为一个字节会给两个桶共用
    
    2. 稀疏存储
        - 数据量少时，使用标志位等标记有连续多少个0，来节省内存

---

#### 3. GeoHash算法
    - 业界比较通用的，用于 地理位置距离排序 的一个算法
    
    - 用途：搜索附近的人
    
##### 3.1 基本思想
    1. 把地球看成一个二维平面
        - 不断等分成一个个小方格（一个大方格分成4个小方格，四叉树），每一个坐标代表一个方格
        - 方格越小，坐标越精确

    2. 将 二维的经纬度 数据映射到 一维的整数
        - 这样所有的元素都将在挂载到一条线上
        - 距离靠近的二维坐标映射到一维后的点之间距离也会很接近
    
    3. 当我们想要计算 「附近的人时」，首先将目标位置映射到这条线上
        - 然后在这个一维的线上获取附近的点就行了
    
##### 3.2 坐标编码划分

        
![image](https://note.youdao.com/yws/public/resource/c9fd6bcc859bb3da286bf905e764f666/xmlnote/6561D29C9920488F915CF6E00426A714/28923)

![image](https://note.youdao.com/yws/public/resource/c9fd6bcc859bb3da286bf905e764f666/xmlnote/78FEAA902D6F4548A6427EA036B5821E/28924)

    1. 在不断等分经度、纬度后
        - 以奇数为纬度，偶数为经度组合
        
    2. 经过以上的组合，数据的顺序大小排序，就变成一个Z字形
        1. 通过这种编码方式，大部分的附近的点都可以拿到
    

###### 为什么这种编码方式，可以将附近的点写到附近
    - 因为每次其实就是经度、或者纬度调整一位

###### 缺点：边界问题
    1. 查看附近的点时
        - 需要将其周边八个方格也考虑上
        - 将自身方格和周边八个方格内的点都遍历一次，再返回符合要求的点
    
    2. 如何获取附近8个点
        - 两个小方格会在 经度或纬度的二进制码上相差1
        - 我们通过 GeoHash 码反向解析出二进制码后，将其经度或纬度（或两者）的二进制码加一，再次组合为 GeoHash 码。

###### redis中的实现
    - Redis中经纬度使用52位的整数进行编码，放进zset中
        - zset的value元素是key
        - score是GeoHash的52位整数值
    
    - 在使用Redis进行Geo查询时，其内部对应的操作其实只是zset(skiplist)的操作
    
    - 通过zset的score进行排序就可以得到坐标附近的其它元素
        - 通过将score还原成坐标值就可以得到元素的原始坐标

    
    

---
#### 4. 资料参考
1. 《数据结构与算法之美》-王争-极客时间
2. https://www.cnblogs.com/wmyskxz/p/12396393.html
3. https://www.jianshu.com/p/1ecf03293b9a
    
    